<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_67) on Thu Jun 18 17:18:36 EDT 2015 -->
<title>SarsaLam</title>
<meta name="date" content="2015-06-18">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SarsaLam";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.EligibilityTrace.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html" target="_top">Frames</a></li>
<li><a href="SarsaLam.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">burlap.behavior.singleagent.learning.tdmethods</div>
<h2 title="Class SarsaLam" class="title">Class SarsaLam</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">burlap.behavior.singleagent.planning.OOMDPPlanner</a></li>
<li>
<ul class="inheritance">
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html" title="class in burlap.behavior.singleagent.learning.tdmethods">burlap.behavior.singleagent.learning.tdmethods.QLearning</a></li>
<li>
<ul class="inheritance">
<li>burlap.behavior.singleagent.learning.tdmethods.SarsaLam</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a>, <a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SarsaLam</span>
extends <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearning</a></pre>
<div class="block">Tabular SARSA(\lambda) implementation [1]. This implementation will work correctly with options [2]. The implementation can either be used for learning or planning,
 the latter of which is performed by running many learning episodes in succession. The number of episodes used for planning can be determined
 by a threshold maximum number of episodes, or by a maximum change in the Q-function threshold.</div>
<dl><dt><span class="strong">Author:</span></dt>
  <dd>James MacGlashan
 
 <p/>
 1. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. <br/>
 2. Sutton, Richard S., Doina Precup, and Satinder Singh. "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning." Artificial intelligence 112.1 (1999): 181-211.</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.EligibilityTrace.html" title="class in burlap.behavior.singleagent.learning.tdmethods">SarsaLam.EligibilityTrace</a></strong></code>
<div class="block">A data structure for maintaining eligibility trace values</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.planning.QComputablePlanner">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.QComputablePlannerHelper.html" title="class in burlap.behavior.singleagent.planning">QComputablePlanner.QComputablePlannerHelper</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.learning.LearningAgent">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.learning.<a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.LearningAgentBookKeeping.html" title="class in burlap.behavior.singleagent.learning">LearningAgent.LearningAgentBookKeeping</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#lambda">lambda</a></strong></code>
<div class="block">the strength of eligibility traces (0 for one step, 1 for full propagation)</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="fields_inherited_from_class_burlap.behavior.singleagent.learning.tdmethods.QLearning">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;burlap.behavior.singleagent.learning.tdmethods.<a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearning</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#episodeHistory">episodeHistory</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#eStepCounter">eStepCounter</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#learningPolicy">learningPolicy</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#learningRate">learningRate</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxEpisodeSize">maxEpisodeSize</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxQChangeForPlanningTermination">maxQChangeForPlanningTermination</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxQChangeInLastEpisode">maxQChangeInLastEpisode</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#numEpisodesForPlanning">numEpisodesForPlanning</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#numEpisodesToStore">numEpisodesToStore</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#qIndex">qIndex</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#qInitFunction">qInitFunction</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#shouldAnnotateOptions">shouldAnnotateOptions</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#shouldDecomposeOptions">shouldDecomposeOptions</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#totalNumberOfSteps">totalNumberOfSteps</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="fields_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#actions">actions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#containsParameterizedActions">containsParameterizedActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#debugCode">debugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#domain">domain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#gamma">gamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#hashingFactory">hashingFactory</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#mapToStateIndex">mapToStateIndex</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#rf">rf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#tf">tf</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#SarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double,%20double)">SarsaLam</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy, the same Q-value initialization everywhere, and places no limit on the number of steps the 
 agent can take in an episode.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#SarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double,%20int,%20double)">SarsaLam</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy, the same Q-value initialization everywhere.</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#SarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double,%20burlap.behavior.singleagent.Policy,%20int,%20double)">SarsaLam</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) with the same Q-value initialization everywhere.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#SarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20burlap.behavior.singleagent.ValueFunctionInitialization,%20double,%20burlap.behavior.singleagent.Policy,%20int,%20double)">SarsaLam</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit,
        double&nbsp;learningRate,
        <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda).</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                      int&nbsp;maxSteps)</code>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html#sarsalamInit(double)">sarsalamInit</a></strong>(double&nbsp;lambda)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_burlap.behavior.singleagent.learning.tdmethods.QLearning">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;burlap.behavior.singleagent.learning.tdmethods.<a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearning</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getAllStoredLearningEpisodes()">getAllStoredLearningEpisodes</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getLastLearningEpisode()">getLastLearningEpisode</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getLastNumSteps()">getLastNumSteps</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getMaxQ(burlap.behavior.statehashing.StateHashTuple)">getMaxQ</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">getQ</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQ(burlap.behavior.statehashing.StateHashTuple,%20burlap.oomdp.singleagent.GroundedAction)">getQ</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQs(burlap.oomdp.core.State)">getQs</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQs(burlap.behavior.statehashing.StateHashTuple)">getQs</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getStateNode(burlap.behavior.statehashing.StateHashTuple)">getStateNode</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)">planFromState</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20burlap.behavior.singleagent.ValueFunctionInitialization,%20double,%20burlap.behavior.singleagent.Policy,%20int)">QLInit</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#resetPlannerResults()">resetPlannerResults</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">runLearningEpisodeFrom</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setLearningPolicy(burlap.behavior.singleagent.Policy)">setLearningPolicy</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setLearningRateFunction(burlap.behavior.learningrate.LearningRate)">setLearningRateFunction</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setMaximumEpisodesForPlanning(int)">setMaximumEpisodesForPlanning</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setMaxQChangeForPlanningTerminaiton(double)">setMaxQChangeForPlanningTerminaiton</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setNumEpisodesToStore(int)">setNumEpisodesToStore</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setQInitFunction(burlap.behavior.singleagent.ValueFunctionInitialization)">setQInitFunction</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#toggleShouldAnnotateOptionDecomposition(boolean)">toggleShouldAnnotateOptionDecomposition</a>, <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#toggleShouldDecomposeOption(boolean)">toggleShouldDecomposeOption</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#addNonDomainReferencedAction(burlap.oomdp.singleagent.Action)">addNonDomainReferencedAction</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getActions()">getActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getAllGroundedActions(burlap.oomdp.core.State)">getAllGroundedActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDebugCode()">getDebugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDomain()">getDomain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getGamma()">getGamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getHashingFactory()">getHashingFactory</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRf()">getRf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRF()">getRF</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTf()">getTf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTF()">getTF</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#plannerInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory)">plannerInit</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setActions(java.util.List)">setActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDebugCode(int)">setDebugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDomain(burlap.oomdp.core.Domain)">setDomain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setGamma(double)">setGamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setRf(burlap.oomdp.singleagent.RewardFunction)">setRf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setTf(burlap.oomdp.core.TerminalFunction)">setTf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#stateHash(burlap.oomdp.core.State)">stateHash</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#toggleDebugPrinting(boolean)">toggleDebugPrinting</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#translateAction(burlap.oomdp.singleagent.GroundedAction,%20java.util.Map)">translateAction</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="lambda">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>lambda</h4>
<pre>protected&nbsp;double lambda</pre>
<div class="block">the strength of eligibility traces (0 for one step, 1 for full propagation)</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SarsaLam</h4>
<pre>public&nbsp;SarsaLam(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy, the same Q-value initialization everywhere, and places no limit on the number of steps the 
 agent can take in an episode. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>QLearning.planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="SarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double, int, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SarsaLam</h4>
<pre>public&nbsp;SarsaLam(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy, the same Q-value initialization everywhere. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>QLearning.planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="SarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double, burlap.behavior.singleagent.Policy, int, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SarsaLam</h4>
<pre>public&nbsp;SarsaLam(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        double&nbsp;qInit,
        double&nbsp;learningRate,
        <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) with the same Q-value initialization everywhere. Note that if the provided policy is derived from the Q-value of this learning agent (as it should be),
 you may need to set the policy to point to this object after call this constructor; the constructor will not do this automatically in case it was by design
 to use the policy that was learned in some other domain. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>QLearning.planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="SarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, burlap.behavior.singleagent.ValueFunctionInitialization, double, burlap.behavior.singleagent.Policy, int, double)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SarsaLam</h4>
<pre>public&nbsp;SarsaLam(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
        <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit,
        double&nbsp;learningRate,
        <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda). Note that if the provided policy is derived from the Q-value of this learning agent (as it should be),
 you may need to set the policy to point to this object after call this constructor; the constructor will not do this automatically in case it was by design
 to use the policy that was learned in some other domain. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>QLearning.planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - a <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent"><code>ValueFunctionInitialization</code></a> object that can be used to initialize the Q-values.</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="sarsalamInit(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sarsalamInit</h4>
<pre>protected&nbsp;void&nbsp;sarsalamInit(double&nbsp;lambda)</pre>
</li>
</ul>
<a name="runLearningEpisodeFrom(burlap.oomdp.core.State, int)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>runLearningEpisodeFrom</h4>
<pre>public&nbsp;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;runLearningEpisodeFrom(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                                     int&nbsp;maxSteps)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">LearningAgent</a></code></strong></div>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state. The episode terminates when a terminal
 state is reached, if the agent decides to determinate the episode, or if the number of steps reaches the provided threshold.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearning</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - The initial state in which the agent will start the episode.</dd><dd><code>maxSteps</code> - the maximum number of steps in the episode</dd>
<dt><span class="strong">Returns:</span></dt><dd>The learning episode events that was performed, stored in an <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> object.</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.EligibilityTrace.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html" target="_top">Frames</a></li>
<li><a href="SarsaLam.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
