<html>
	<head>
		<title>BURLAP: FAQ</title>
		<script src="../google-code-prettify/run_prettify.js?skin=desert"></script>
		<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
	</head>
	<body>
	
		<div id="nav">
			
			<span id="nav-content">
			<a href="index.html">BURLAP</a>
			<span id="nav-items"><a href="index.html">Home</a> | <a href="updates.html">Updates</a> | <a href="information.html">Information</a> | <a href="faq.html">F.A.Q.</a> | <a href="tutorials/index.html">Tutorials</a> | <a href="doc/index.html">Java Doc</a></span>
			</span>

		</div>
		<div id="page">
			<div id="page-content">
				<h1>F.A.Q.</h1>
				<h2>Question Index</h2>
				<ul>
				<li><a href="#whatIsBurlap">What is BURLAP?</a></li>
				<li><a href="#license">What is BURLAP's software license?</a></li>
				<li><a href="#contact">Who do I contact if I have a question or comment?</a></li>
				<li><a href="#java">Why Java and not language x?</a></li>
				<li><a href="#oomdp">What is an object-oriented Markov decision process (OO-MDP)?</a></li>
				<li><a href="#grounded">What is the difference between an Action and a GroundedAction? What about a PropositionalFunction and a GroundedProp?</a></li>
				<li><a href="#abstractGrounded">What is an AbstractGroundedAction class?</a></li>
				<li><a href="#hashFactory">What is a HashableStateFactory?</a></li>
				<li><a href="#identifierInvariance">What is object independence invariance?</a></li>
				<li><a href="#whyNotInvariance">If object identifier independence leads to smaller state spaces, why wouldn't I want to use it?</a></li>
				<li><a href="#terminal">How are terminal states defined in BURLAP?</a></li>
				<li><a href="#stateSpace">Domains don't seem to provide access to the entire state space. Why not and how can I get it?</a></li>
				<li><a href="#transitionDynamics">Where are transition dynamics defined?</a></li>
				<li><a href="#preconditions">Can actions have preconditions?</a></li>
				<li><a href="#sgAgentAction">What is an SGAgentAction class?</a></li>
				<li><a href="#pog">What is a parameter order group?</a></li>
				<li><a href="#memory">My planning or learning algorithm is running out of memory, is there anything that I can do?</a></li>
				<li><a href="#robot">Can I have BURLAP control a robot?</a></li>
				<li><a href="#minecraft">I heard that you can use BURLAP for AI in Minecraft, how can I do that?</a></li>
				<li><a href="#cite">How do I cite BURLAP?</a></li>
				<li><a href="#v1">Is the FAQ and Java doc for version 1 of BURLAP still available?</a></li>
				</ul>



				<h3>Answers</h3>
				<ul>
					<li><b><a name="whatIsBurlap"/>What is BURLAP?</b>
					<p>
					BURLAP stands for Brown-UMBC Reinforcement Learning And Planning and is a Java library for the use and development of single or multi-agent planning and learning algorithms and domains to accompany them.
					</p>
					</li>
					<li><b><a name="license"/>What is BURLAP's software license?</b>
					<p>
					BURLAP is licensed under LGPL. In brief, that means you can use it for free and even link to it in sold software.
					</p>
					</li>
					<li><b><a name="contact"/>Who do I contact if I have a question or comment?</b>
					<p>
					You can either field the question to the community in our <a href="https://groups.google.com/forum/#!forum/burlap-discussion">Google group</a> or you can send an email to the creator, James MacGlashan, at jmacglashan at cs dot brown dot edu.
					</p>
					</li>
					<li><b><a name="java"/>Why Java and not language x?</b>
					<p>
					Java provides a nice balance between high portability and efficiency, while also being fairly well known with a wide range of available libraries. Additionally, many modern languages, such as Scala and Groovy, compile to the JVM, which makes BURLAP instantly compatible with them.
					</p>
					</li>
					<li><b><a name="oomdp"/>What is an object-oriented Markov decision process (OO-MDP)?</b>
					<p>
					This topic is more fully described on <a href="tutorials/bd/p2.html">page 2 of the Building a Domain tutorial</a>. In short, an OO-MDP defines states as a set of objects, each with their own attribute values, and adds a set of propositional functions that operate on the objects in a state, thereby providing additional high-level information. This representation is very powerful and allows for a range of different kinds of problems to be easily defined.
					</p>
					</li>
					<li><b><a name="grounded"/>What is the difference between an <a href="doc/burlap/oomdp/singleagent/Action.html">Action</a> and a <a href="doc/burlap/oomdp/singleagent/GroundedAction.html">GroundedAction</a>? What about a <a href="doc/burlap/oomdp/core/PropositionalFunction.html">PropositionalFunction</a> and a <a href="http://burlap.cs.brown.edu/doc/burlap/oomdp/core/GroundedProp.html">GroundedProp</a>?</b>
					<p>
					First, be sure read the Java documentation for these classes which provides a good deal of information. In brief, an Action is subclassed and instantiated to define your MDP actions; that means the action name, its preconditions, parameterizations, and transition dynamics. Because actions can be defined to be parameterized, decisions that an agent makes are not only over the space of actions definitions, but the space of possible parameterizations for each action definition. As a consequence, there needs to be a way for agents to refer to which action-parameterization they're considering. The GroundedAction serves this purpose by containing a reference to an Action, as well as parameter assignments with which the action will be applied.
					</p>
					<p>
					When you subclass Action, the kinds of parameterizations your action supports are defined by the getAssociatedGroundedAction() and getAllApplicableGroundedActions(burlap.oomdp.core.states.State) methods, which should return a subclass of GroundedAction that contains the possible parameterizations. Because you can create your own subclasses of GroundedAction, you can define any kind of action parameterization that you'd like! From continuous valued parameters, to STRIPs-like object references.
					</p>
					<p>
					If your action is not parameterized and has no preconditions, you should consider subclassing <a href="doc/burlap/oomdp/singleagent/common/SimpleAction.html">SimpleAction</a>, which implements many of the Action methods and returns the parameter-free <a href="doc/burlap/oomdp/singleagent/common/SimpleGroundedAction.html">SimpleGroundedAction</a>.
					</p>
					<p>
					The difference between PropositionalFunction and GroundedProp is similar; PropositionalFunction defines the propositional function and GroundedProp is a reference to the PropositionalFunction along with the parameters with which to evaluate it. In this case, however, the parameters to propositional functions are always OO-MDP objects in the state.</p>
					</li>
					<li><b><a name="abstractGrounded"/>What is an <a href="doc/burlap/oomdp/core/AbstractGroundedAction.html">AbstractGroundedAction</a> class?</b>
					<p>
					AbstractGroundedAction is the common interface for the <a href="doc/burlap/oomdp/singleagent/GroundedAction.html">GroundedAction</a> class and other and acton groundings used in other problem types (for example, <a href="doc/burlap/oomdp/stochasticgames/agentactions/GroundedSGAgentAction.html">GroundedSGAgentAction</a> in stochastic games). This common interface allows tools in BURLAP be re-used across different problem types. For example, the <a href="doc/burlap/behavior/policy/Policy.html">Policy</a> class can be used in both single agent problems and stochastic games problems, because it returns AbstractGroundedAction implementations, rather than a single problem type's grounded action.
					</p>
					</li>
					<li><b><a name="hashFactory"/>What is a <a href="doc/burlap/oomdp/statehashing/HashableStateFactory.html">HashableStateFactory?</a></b>
					<p>
					Tabular learning and planning algorithms need a way to quickly look up values or stored actions (or otherwise) for different states, which makes Java HashMaps and HashSets especially appealing. Of course, that requires that we be able to compute hash codes for OO-MDP <a href="doc/burlap/oomdp/core/states/State.html">State</a> objects and perform equality evaluations between them. Depending the kind of problem you're solving there may be different ways that you need to compute the hash code and perform equality evaluations. For example, perhaps you want to plan in an abstract space that ignores certain objects or attribute values. Or maybe you need to discretize real-valued attributes before comparing the states. Or maybe you don't want to use object identifier invariance.</p>
					<p>
					Since different problems may require different ways of hashing and comparing states, different HashableStateFactory implementations will produce different <a href="doc/burlap/oomdp/statehashing/HashableState.html">HashableState</a> objects that compute hash codes and perform state equality evaluations differently. However, unless you want to do something special, (like state abstraction) use <a href="doc/burlap/oomdp/statehashing/SimpleHashableStateFactory.html">SimpleHashableStateFactory</a>. You can also always implement your own if you need special functionality not already supported in BURLAP!
					</p>
					</li>
					<li><b><a name="identifierInvariance"/>What is object identifier independence?</b>
					<p>For a larger discussion of this topic, see <a href="tutorials/bd/p2.html">page 2 of the Building a Domain tutorial</a>. In short, if a domain is object identifier independent, then it means that the equality of two states is independent of the order of the objects (or their name) in the states. Instead, two states will be considered equal as long as there is a bijection between their objects such that each matched object is equal to one another. Using object identifier independence results in a compression of the state space size since you don't have to treat every ordering of the same objects as different states.</p>
					</li>
					<li><b><a name="whyNotInvariance"/>If object identifier independence leads to smaller state spaces, why wouldn't I want to use it?</b>
					<p>
					When you don't! :-) For example, if you want to define a goal in which the condition for a <i>specific</i> object is satisfied, you need to differentiate between objects with different identifiers.</p>
					<p>Additionally, if you are creating a relational domain, then you must have object identifier dependence, because being invariant to object identifiers in a relational domain would require solving graph isomorphism which is thought to be NP-hard. So while detecting graph isomorphism is doable, BURLAP does not implement object identifier independence in relational domains since it's not tractable.</p>
					</li>
					<li><b><a name="terminal"/>How are terminal states defined in BURLAP?</b>
					<p>
					Terminal states are defined with an object that implements the <a href="doc/burlap/oomdp/core/TerminalFunction.html">TerminalFunction</a> interface. Following the Sutton and Barto paradigm, planning and learning algorithms in BURLAP mathematically interpret terminal states as states from which the agent deterministically transitions back to the same state with a reward of zero. This is equivalent to all action ceasing once a terminal state is reached. Because terminal states are indicated with a TerminalFunction class, this property of the transition dynamics does not need to be specifically coded into the action transition dynamics, which makes it easy to define various ad hoc tasks for the same domain.</p>
					<p>
					Given this interpretation, the value of terminal states should be fixed at zero (and is in the existing BURLAP planning and learning algorithms). If you are are student reading from the Russell Norvig AI textbook and want to implement their small grid world, keep in mind that that their small grid world  treats the terminal state has having a non-zero value.</p>
					</li> 
					<li><b><a name="stateSpace"/>Domains don't seem to provide access to the entire state space. Why not and how can I get it?</b>
					<p>
					In an OO-MDP, the state space is infinite because you can always just imagine another world with an additional object. Although in practice your state space may always be well defined, the domain generators in BURLAP can support much more than any single instance, which may make enumerating the state space for any domain instance non-trivial. For example, even in grid worlds you can imagine any number of different grid worlds. In other cases, it can just be hard to manually enumerate all possible state, which would make requiring it for domains a burden on the designer.</p>
					<p>
					However, if you'd like to gather all the possible states from a domain instance that you've created, a good way to go about this is to let BURLAP do the heavy lifting for you by using the <a href="doc/burlap/behavior/singleagent/auxiliary/StateReachability.html">StateReachability</a> class, which takes as input a source state and domain, and returns all states that are reachable from the state. If your domain has states that are disconnected from each other, then you may need to run it from multiple seed states in each disconnected component. You may also find the <a href="http://burlap.cs.brown.edu/doc/burlap/behavior/singleagent/auxiliary/StateEnumerator.html">StateEnumerator</a> class helpful, which will let you iteratively add additional states to its set and assign a unique identifier to each.
					</p>
					<p>
					If you are working in a continuous state space, then the number of states is probably uncountably infinite, which obviously makes state enumeration impossible; however, if you want a representation of the space, you may want to consider the <a href="doc/burlap/behavior/singleagent/auxiliary/StateGridder.html">StateGridder</a> class, which will sample states in the space along a regular grid that you can define.
					</p>
					<p>
					And if you're using a planning algorithm that needs the full state space, such as value iteration, the implementations in BURLAP will automatically handle enumeration of the states from the source state that you give it.
					</p>
					</li>
					<li><b><a name="transitionDynamics"/>Where are transition dynamics defined?</b>
					<p>
					Transition dynamics for a single-agent domain are defined in the <a href="doc/burlap/oomdp/singleagent/Action.html">Action</a> classes that you (or an existing domain) implement. Specifically, there are two methods used for defining transition dynamics. The performActionHelper(State, GroundedAction) and, if your Action class implements <a href="doc/burlap/oomdp/singleagent/FullActionModel.html">FullActionModel</a>, getTransitions(State GroundedAction). The performActionHelper method, as the name implies performs the action on the given state (and the given parameters, if any, in the GroundedAction argument) and returns the outcome state. If the domain is stochastic, then the method should randomly sample an outcome state according to the distribution. Note that this method does not require the probability of the sampled outcome state to be returned, which in some domains may be non-trivial to compute. This method must be implemented to implement an Action.
					</p>
					<p>The getTransitions method returns a list of all the possible outcome states with non-zero probability as well as their probability of occurring.
					This method only needs to be implemented if your action implements the optional interface FullActionModel, because for some domains it is impossible to enumerate all possible outcomes. However, some algorithms, such as <a href="doc/burlap/behavior/singleagent/planning/stochastic/DynamicProgramming.html">DynamicProgramming</a> algorithms, require being able to access the fully enumerated transition dynamics. So if you plan on using these algorithms with your domain, your Action will need to implement the interface and method.
					</p>
					<p>
					For stochastic games problems, similar methods that need to be overridden exist in the <a href="doc/burlap/oomdp/stochasticgames/JointActionModel.html">JointActionModel</a> abstract class: actionHelper(State, JointAction) and transitionProbsFor(State, JointAction), respectively.
					</p>
					</li>
					<li><b><a name="preconditions"/>Can actions have preconditions?</b>
					<p>
					Yes! When you subclass <a href="doc/burlap/oomdp/singleagent/Action.html">Action</a>, one of the methods you must implement is applicableInState(State, GroundedAction), which should return true in states where you preconditions are satisfied and false in states where they are not. For stochastic games, the <a href="doc/burlap/oomdp/stochasticgames/agentactions/SGAgentAction.html">SGAgentAction</a> has a method with the same name for the same purpose.
					</p>
					</li>
					<li><b><a name="sgAgentAction"/>What is a <a href="doc/burlap/oomdp/stochasticgames/agentactions/SGAgentAction.html">SGActionACtion</a> class?</b>
					<p>
					A SGAgentAction class is used to define stochastic games problems. Stochastic games are formalism for a multi-agent problem. In the definition, each agent in the world has a set of individual actions that they apply and at each time step, they each choose from their set of actions and execute them at the same time. Similar, to the single-agent problem  <a href="doc/burlap/oomdp/singleagent/Action.html">Action</a> class, the SGAgentAction class is used to define the name, preconditions, and parameterizations of an action that an agent in a stochastic games problem can take. Since states in a stochastic game change as a function of joint actions taken by all agents in the world, SGAgentAction does not have transition dynamics defined in it. Instead, transition dynamics for stochastic games are defined in the `<a href="doc/burlap/oomdp/stochasticgames/JointActionModel.html">JointActionModel</a> abstract class.
					</p>
					</li>
					<li><b><a name="pog"/>What is a parameter order group?</b>
					<p>
					You will see this term used in the definition of STRIPs-like <a href="doc/burlap/oomdp/singleagent/ObjectParameterizedAction.html">ObjectParameterizedAction</a> implementations and the <a href="doc/burlap/oomdp/core/PropositionalFunction.html">PropositionalFunction</a> class. A parameter order group is used with OO-MDP object parameters to specify whether there is symmetry between parameters. That is, parameters that belong to the same parameter order group (POG) can have their values swapped without changing the effect of the action or evaluation of the propositional function. For example, consider the propositional function prototype touching(X, Y), which returns true when the object assigned to X is touching the object assigned to Y. This evaluation should be be transitive. That is, if touching(a, b) is true, then touching(b, a) is true (and inversely when one evaluates to false, flipping the parameters should still result in a false evaluation). To encode that the parameters are transitive, we assign them to the same POG (which can be named anything as long as it's the same name for both). If they are not transitive, then we would assign different POGs to them. If you use an ObjectParameterizedAction constructor or PropositionalFunction constructor without the POG values argument, it will automatically assign each parameter to a different POG (that is, non-transitivity is the default assumption).
					</p>
					<p>
					Specifying the parameter transitivity with POGs is useful because when you request a list of all grounded versions of an ObjectParameterizedAction (with the getAllApplicableGroundedActions(State) method) or propositional function (with the getAllGroundedPropsForState(State) method), it will not produce a grounding that is transitively identical to another already in the list. In our touching(X, Y) example, for instance, it will return a list with only the grounding for touching(a, b), or touching(b, a), but not both.
					</p>
					</li>
					<li><b><a name="memory"/>My planning or learning algorithm is running out of memory, is there anything that I can do?</b>
					<p>
					Possibly. The first thing to do is to make sure that Java's JVM is being given a large enough heap. If it's not, it's possible that it's artificially using less memory than you have. To set the amount of memory Java's JVM can use, you want to add a -Xmx argument when you call java; e.g., java -Xmx2048M [class path here]. The -Xmx argument lets you specify the heap size. In the example, it would provide it with 2048MB (2GB). If you're running in Eclipse or IntelliJ, then in the run configuration you should find a text field that lets you set your VM arguments; that's where you would put that flag.
					</p>
					<p>
					If you're still running out of memory then there are a couple of things to consider. First, try and figure out if there is a more compact way to define your states. For example, do you really need as many OO-MDP objects you've defined, or can they be compressed into a smaller set?
					</p>
					<p>
					Finally, if you're still running out memory, you should considering writing your own implementation of the <a href="doc/burlap/oomdp/core/states/State.html">State</a> interface that allows for the most efficient management of your state data. It's possible the standard <a href="doc/burlap/oomdp/core/states/MutableState.html">MutableState</a> implementation that is mostly used in BURLAP domains is too general and is being wasteful for your specific domain.
					</p>
					<li><b><a name="robot"/>Can I have BURLAP control a robot?</b>
					<p>
					Sure! There are two ways you can do this. You can (1) implement
					your own <a href="doc/burlap/oomdp/singleagent/environment/Environment.html">Environment</a> class to manage the connection, control, and state perception of your robot; or (2) use our BURLAP library extension 
					(<a href="https://github.com/h2r/burlap_rosbridge" target="external">burlap_rosbridge</a>) that has a standard Environment implementation for communicating with robots controlled with <a href="http://www.ros.org" target="external">ROS</a> over <a href="http://wiki.ros.org/rosbridge_suite" target="external">Rosbridge</a>. 
					</p>
					<p>
					When using <a href="https://github.com/h2r/burlap_rosbridge" target="external">burlap_rosbridge</a> it is expected that you create a ROS topic that is publishing BURLAP state messages (formatted according our defined <a href="https://github.com/h2r/burlap_msgs" target="external">burlap_msgs</a> type) and that there is a topic BURLAP can push to that accepts action commands as a string type. See burlap_rosbridge's <a href="https://github.com/h2r/burlap_rosbridge" target="external">github
					page</a> for more information on how to use it.
					</li>
					<li><b><a name="minecraft"/>I heard that you can use BURLAP for AI in Minecraft, how can I do that?</b>
					<p>
					Yes, we have been building a mod for <a href="https://minecraft.net/" target="external">Minecraft</a> that allows you to use BURLAP's planning and learning algorithms to control the player. For more information on that project, see its <a href="https://github.com/h2r/burlapcraft" target="external">github page</a> and its accompanying <a href="https://github.com/h2r/burlapcraft/wiki" target="external">wiki page</a>.
					</p>
					</li>
					<li><b><a name="cite"/>How do I cite BURLAP?</b>
					<p>
					For the moment, you'll have to cite this web page and can use James MacGlashan as the author. An academic publication is forthcoming, which you can use once it's available.
					</p>
					</li>
					<li><b><a name="v1"/>Is the FAQ and Java doc for version 1 of BURLAP still available?</b>
					<p>Yes, you can access the older FAQ <a href="faqv1.html">here</a>, and the older Java doc <a href="doc_v1/index.html">here</a>.</p>
					</li>

				</ul>


				


			</div>
		</div>
		
	</body>
</html>