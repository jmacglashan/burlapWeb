<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_67) on Fri May 22 18:24:52 EDT 2015 -->
<title>QLearning</title>
<meta name="date" content="2015-05-22">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="QLearning";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/QLearning.html" target="_top">Frames</a></li>
<li><a href="QLearning.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">burlap.behavior.singleagent.learning.tdmethods</div>
<h2 title="Class QLearning" class="title">Class QLearning</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">burlap.behavior.singleagent.planning.OOMDPPlanner</a></li>
<li>
<ul class="inheritance">
<li>burlap.behavior.singleagent.learning.tdmethods.QLearning</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a>, <a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/SarsaLam.html" title="class in burlap.behavior.singleagent.learning.tdmethods">SarsaLam</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">QLearning</span>
extends <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a>
implements <a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a>, <a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></pre>
<div class="block">Tabular Q-learning algorithm [1]. This implementation will work correctly with Options [2]. The implementation can either be used for learning or planning,
 the latter of which is performed by running many learning episodes in succession. The number of episodes used for planning can be determined
 by a threshold maximum number of episodes, or by a maximum change in the Q-function threshold.
 
 <p/>
 1. Watkins, Christopher JCH, and Peter Dayan. "Q-learning." Machine learning 8.3-4 (1992): 279-292. <br/>
 2. Sutton, Richard S., Doina Precup, and Satinder Singh. "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning." Artificial intelligence 112.1 (1999): 181-211.</div>
<dl><dt><span class="strong">Author:</span></dt>
  <dd>James MacGlashan</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.planning.QComputablePlanner">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.QComputablePlannerHelper.html" title="class in burlap.behavior.singleagent.planning">QComputablePlanner.QComputablePlannerHelper</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.learning.LearningAgent">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.learning.<a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.LearningAgentBookKeeping.html" title="class in burlap.behavior.singleagent.learning">LearningAgent.LearningAgentBookKeeping</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.LinkedList&lt;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#episodeHistory">episodeHistory</a></strong></code>
<div class="block">the saved previous learning episodes</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#eStepCounter">eStepCounter</a></strong></code>
<div class="block">A counter for counting the number of steps in an episode that have been taken thus far</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#learningPolicy">learningPolicy</a></strong></code>
<div class="block">The learning policy to use.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#learningRate">learningRate</a></strong></code>
<div class="block">The learning rate function used.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxEpisodeSize">maxEpisodeSize</a></strong></code>
<div class="block">The maximum number of steps that will be taken in an episode before the agent terminates a learning episode</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxQChangeForPlanningTermination">maxQChangeForPlanningTermination</a></strong></code>
<div class="block">The maximum allowable change in the Q-function during an episode before the planning method terminates.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#maxQChangeInLastEpisode">maxQChangeInLastEpisode</a></strong></code>
<div class="block">The maximum Q-value change that occurred in the last learning episode.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#numEpisodesForPlanning">numEpisodesForPlanning</a></strong></code>
<div class="block">The maximum number of episodes to use for planning</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#numEpisodesToStore">numEpisodesToStore</a></strong></code>
<div class="block">The number of the most recent learning episodes to store.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.Map&lt;<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>,<a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearningStateNode</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#qIndex">qIndex</a></strong></code>
<div class="block">The tabular mapping from states to Q-values</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#qInitFunction">qInitFunction</a></strong></code>
<div class="block">The object that defines how Q-values are initialized.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#shouldAnnotateOptions">shouldAnnotateOptions</a></strong></code>
<div class="block">Whether decomposed options should have their primitive actions annotated with the options name in the returned <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#shouldDecomposeOptions">shouldDecomposeOptions</a></strong></code>
<div class="block">Whether options should be decomposed into actions in the returned <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#totalNumberOfSteps">totalNumberOfSteps</a></strong></code>
<div class="block">The total number of learning steps performed by this agent.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="fields_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#actions">actions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#containsParameterizedActions">containsParameterizedActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#debugCode">debugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#domain">domain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#gamma">gamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#hashingFactory">hashingFactory</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#mapToStateIndex">mapToStateIndex</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#rf">rf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#tf">tf</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLearning(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double)">QLearning</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate)</code>
<div class="block">Initializes Q-learning with 0.1 epsilon greedy policy, the same Q-value initialization everywhere, and places no limit on the number of steps the 
 agent can take in an episode.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLearning(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double,%20int)">QLearning</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate,
         int&nbsp;maxEpisodeSize)</code>
<div class="block">Initializes Q-learning with 0.1 epsilon greedy policy, the same Q-value initialization everywhere.</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLearning(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20double,%20double,%20burlap.behavior.singleagent.Policy,%20int)">QLearning</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate,
         <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
         int&nbsp;maxEpisodeSize)</code>
<div class="block">Initializes the same Q-value initialization everywhere.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLearning(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20burlap.behavior.singleagent.ValueFunctionInitialization,%20double,%20burlap.behavior.singleagent.Policy,%20int)">QLearning</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit,
         double&nbsp;learningRate,
         <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
         int&nbsp;maxEpisodeSize)</code>
<div class="block">Initializes the algorithm.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getAllStoredLearningEpisodes()">getAllStoredLearningEpisodes</a></strong>()</code>
<div class="block">Returns all saved <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getLastLearningEpisode()">getLastLearningEpisode</a></strong>()</code>
<div class="block">Returns the last learning episode of the agent.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getLastNumSteps()">getLastNumSteps</a></strong>()</code>
<div class="block">Returns the number of steps taken in the last episode;</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getMaxQ(burlap.behavior.statehashing.StateHashTuple)">getMaxQ</a></strong>(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</code>
<div class="block">Returns the maximum Q-value in the hashed stated.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">getQ</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
    <a href="../../../../../burlap/oomdp/core/AbstractGroundedAction.html" title="class in burlap.oomdp.core">AbstractGroundedAction</a>&nbsp;a)</code>
<div class="block">Returns the <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQ(burlap.behavior.statehashing.StateHashTuple,%20burlap.oomdp.singleagent.GroundedAction)">getQ</a></strong>(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s,
    <a href="../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;a)</code>
<div class="block">Returns the Q-value for a given hashed state and action.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQs(burlap.oomdp.core.State)">getQs</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</code>
<div class="block">Returns a <code>List</code> of <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getQs(burlap.behavior.statehashing.StateHashTuple)">getQs</a></strong>(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</code>
<div class="block">Returns the possible Q-values for a given hashed stated.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearningStateNode</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#getStateNode(burlap.behavior.statehashing.StateHashTuple)">getStateNode</a></strong>(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</code>
<div class="block">Returns the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object stored for the given hashed state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)">planFromState</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</code>
<div class="block">This method will cause the planner to begin planning from the specified initial state</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#QLInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory,%20burlap.behavior.singleagent.ValueFunctionInitialization,%20double,%20burlap.behavior.singleagent.Policy,%20int)">QLInit</a></strong>(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
      <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
      <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
      double&nbsp;gamma,
      <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
      <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInitFunction,
      double&nbsp;learningRate,
      <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
      int&nbsp;maxEpisodeSize)</code>
<div class="block">Initializes the algorithm.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#resetPlannerResults()">resetPlannerResults</a></strong>()</code>
<div class="block">Use this method to reset all planner results so that planning can be started fresh with a call to <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a>
 as if no planning had ever been performed before.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">runLearningEpisodeFrom</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</code>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></strong>(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                      int&nbsp;maxSteps)</code>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setLearningPolicy(burlap.behavior.singleagent.Policy)">setLearningPolicy</a></strong>(<a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;p)</code>
<div class="block">Sets which policy this agent should use for learning.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setLearningRateFunction(burlap.behavior.learningrate.LearningRate)">setLearningRateFunction</a></strong>(<a href="../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a>&nbsp;lr)</code>
<div class="block">Sets the learning rate function to use</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setMaximumEpisodesForPlanning(int)">setMaximumEpisodesForPlanning</a></strong>(int&nbsp;n)</code>
<div class="block">Sets the maximum number of episodes that will be performed when the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setMaxQChangeForPlanningTerminaiton(double)">setMaxQChangeForPlanningTerminaiton</a></strong>(double&nbsp;m)</code>
<div class="block">Sets a max change in the Q-function threshold that will cause the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> to stop planning
 when it is achieved.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setNumEpisodesToStore(int)">setNumEpisodesToStore</a></strong>(int&nbsp;numEps)</code>
<div class="block">Tells the agent how many <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects representing learning episodes to internally store.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#setQInitFunction(burlap.behavior.singleagent.ValueFunctionInitialization)">setQInitFunction</a></strong>(<a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit)</code>
<div class="block">Sets how to initialize Q-values for previously unexperienced state-action pairs.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#toggleShouldAnnotateOptionDecomposition(boolean)">toggleShouldAnnotateOptionDecomposition</a></strong>(boolean&nbsp;toggle)</code>
<div class="block">Sets whether options that are decomposed into primitives will have the option that produced them and listed.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#toggleShouldDecomposeOption(boolean)">toggleShouldDecomposeOption</a></strong>(boolean&nbsp;toggle)</code>
<div class="block">Sets whether the primitive actions taken during an options will be included as steps in produced EpisodeAnalysis objects.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#addNonDomainReferencedAction(burlap.oomdp.singleagent.Action)">addNonDomainReferencedAction</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getActions()">getActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getAllGroundedActions(burlap.oomdp.core.State)">getAllGroundedActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDebugCode()">getDebugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDomain()">getDomain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getGamma()">getGamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getHashingFactory()">getHashingFactory</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRf()">getRf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRF()">getRF</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTf()">getTf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTF()">getTF</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#plannerInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory)">plannerInit</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setActions(java.util.List)">setActions</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDebugCode(int)">setDebugCode</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDomain(burlap.oomdp.core.Domain)">setDomain</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setGamma(double)">setGamma</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setRf(burlap.oomdp.singleagent.RewardFunction)">setRf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setTf(burlap.oomdp.core.TerminalFunction)">setTf</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#stateHash(burlap.oomdp.core.State)">stateHash</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#toggleDebugPrinting(boolean)">toggleDebugPrinting</a>, <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#translateAction(burlap.oomdp.singleagent.GroundedAction,%20java.util.Map)">translateAction</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="qIndex">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>qIndex</h4>
<pre>protected&nbsp;java.util.Map&lt;<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>,<a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearningStateNode</a>&gt; qIndex</pre>
<div class="block">The tabular mapping from states to Q-values</div>
</li>
</ul>
<a name="qInitFunction">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>qInitFunction</h4>
<pre>protected&nbsp;<a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a> qInitFunction</pre>
<div class="block">The object that defines how Q-values are initialized.</div>
</li>
</ul>
<a name="learningRate">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>learningRate</h4>
<pre>protected&nbsp;<a href="../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a> learningRate</pre>
<div class="block">The learning rate function used.</div>
</li>
</ul>
<a name="learningPolicy">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>learningPolicy</h4>
<pre>protected&nbsp;<a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a> learningPolicy</pre>
<div class="block">The learning policy to use. Typically these will be policies that link back to this object so that they change as the Q-value estimate change.</div>
</li>
</ul>
<a name="maxEpisodeSize">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxEpisodeSize</h4>
<pre>protected&nbsp;int maxEpisodeSize</pre>
<div class="block">The maximum number of steps that will be taken in an episode before the agent terminates a learning episode</div>
</li>
</ul>
<a name="eStepCounter">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eStepCounter</h4>
<pre>protected&nbsp;int eStepCounter</pre>
<div class="block">A counter for counting the number of steps in an episode that have been taken thus far</div>
</li>
</ul>
<a name="numEpisodesForPlanning">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numEpisodesForPlanning</h4>
<pre>protected&nbsp;int numEpisodesForPlanning</pre>
<div class="block">The maximum number of episodes to use for planning</div>
</li>
</ul>
<a name="maxQChangeForPlanningTermination">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxQChangeForPlanningTermination</h4>
<pre>protected&nbsp;double maxQChangeForPlanningTermination</pre>
<div class="block">The maximum allowable change in the Q-function during an episode before the planning method terminates.</div>
</li>
</ul>
<a name="maxQChangeInLastEpisode">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxQChangeInLastEpisode</h4>
<pre>protected&nbsp;double maxQChangeInLastEpisode</pre>
<div class="block">The maximum Q-value change that occurred in the last learning episode.</div>
</li>
</ul>
<a name="episodeHistory">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>episodeHistory</h4>
<pre>protected&nbsp;java.util.LinkedList&lt;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt; episodeHistory</pre>
<div class="block">the saved previous learning episodes</div>
</li>
</ul>
<a name="numEpisodesToStore">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numEpisodesToStore</h4>
<pre>protected&nbsp;int numEpisodesToStore</pre>
<div class="block">The number of the most recent learning episodes to store.</div>
</li>
</ul>
<a name="shouldDecomposeOptions">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>shouldDecomposeOptions</h4>
<pre>protected&nbsp;boolean shouldDecomposeOptions</pre>
<div class="block">Whether options should be decomposed into actions in the returned <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</li>
</ul>
<a name="shouldAnnotateOptions">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>shouldAnnotateOptions</h4>
<pre>protected&nbsp;boolean shouldAnnotateOptions</pre>
<div class="block">Whether decomposed options should have their primitive actions annotated with the options name in the returned <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</li>
</ul>
<a name="totalNumberOfSteps">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>totalNumberOfSteps</h4>
<pre>protected&nbsp;int totalNumberOfSteps</pre>
<div class="block">The total number of learning steps performed by this agent.</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="QLearning(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>QLearning</h4>
<pre>public&nbsp;QLearning(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate)</pre>
<div class="block">Initializes Q-learning with 0.1 epsilon greedy policy, the same Q-value initialization everywhere, and places no limit on the number of steps the 
 agent can take in an episode. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd></dl>
</li>
</ul>
<a name="QLearning(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>QLearning</h4>
<pre>public&nbsp;QLearning(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate,
         int&nbsp;maxEpisodeSize)</pre>
<div class="block">Initializes Q-learning with 0.1 epsilon greedy policy, the same Q-value initialization everywhere. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd></dl>
</li>
</ul>
<a name="QLearning(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, double, double, burlap.behavior.singleagent.Policy, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>QLearning</h4>
<pre>public&nbsp;QLearning(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         double&nbsp;qInit,
         double&nbsp;learningRate,
         <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
         int&nbsp;maxEpisodeSize)</pre>
<div class="block">Initializes the same Q-value initialization everywhere. Note that if the provided policy is derived from the Q-value of this learning agent (as it should be),
 you may need to set the policy to point to this object after call this constructor; the constructor will not do this automatically in case it was by design
 to use the policy that was learned in some other domain. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - the initial Q-value to user everywhere</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd></dl>
</li>
</ul>
<a name="QLearning(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, burlap.behavior.singleagent.ValueFunctionInitialization, double, burlap.behavior.singleagent.Policy, int)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>QLearning</h4>
<pre>public&nbsp;QLearning(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
         <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
         <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
         double&nbsp;gamma,
         <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
         <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit,
         double&nbsp;learningRate,
         <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
         int&nbsp;maxEpisodeSize)</pre>
<div class="block">Initializes the algorithm. Note that if the provided policy is derived from the Q-value of this learning agent (as it should be),
 you may need to set the policy to point to this object after call this constructor; the constructor will not do this automatically in case it was by design
 to use the policy that was learned in some other domain. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInit</code> - a <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent"><code>ValueFunctionInitialization</code></a> object that can be used to initialize the Q-values.</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="QLInit(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.statehashing.StateHashFactory, burlap.behavior.singleagent.ValueFunctionInitialization, double, burlap.behavior.singleagent.Policy, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>QLInit</h4>
<pre>protected&nbsp;void&nbsp;QLInit(<a href="../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
          <a href="../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
          <a href="../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
          double&nbsp;gamma,
          <a href="../../../../../burlap/behavior/statehashing/StateHashFactory.html" title="interface in burlap.behavior.statehashing">StateHashFactory</a>&nbsp;hashingFactory,
          <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInitFunction,
          double&nbsp;learningRate,
          <a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
          int&nbsp;maxEpisodeSize)</pre>
<div class="block">Initializes the algorithm. By default the agent will only save the last learning episode and a call to the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>hashingFactory</code> - the state hashing factory to use for Q-lookups</dd><dd><code>qInitFunction</code> - a <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent"><code>ValueFunctionInitialization</code></a> object that can be used to initialize the Q-values.</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in a learning episode for the agent stops trying.</dd></dl>
</li>
</ul>
<a name="setLearningRateFunction(burlap.behavior.learningrate.LearningRate)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRateFunction</h4>
<pre>public&nbsp;void&nbsp;setLearningRateFunction(<a href="../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a>&nbsp;lr)</pre>
<div class="block">Sets the learning rate function to use</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lr</code> - the learning rate function to use</dd></dl>
</li>
</ul>
<a name="setQInitFunction(burlap.behavior.singleagent.ValueFunctionInitialization)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setQInitFunction</h4>
<pre>public&nbsp;void&nbsp;setQInitFunction(<a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent">ValueFunctionInitialization</a>&nbsp;qInit)</pre>
<div class="block">Sets how to initialize Q-values for previously unexperienced state-action pairs.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>qInit</code> - a <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent"><code>ValueFunctionInitialization</code></a> object that can be used to initialize the Q-values.</dd></dl>
</li>
</ul>
<a name="setLearningPolicy(burlap.behavior.singleagent.Policy)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningPolicy</h4>
<pre>public&nbsp;void&nbsp;setLearningPolicy(<a href="../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;p)</pre>
<div class="block">Sets which policy this agent should use for learning.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>p</code> - the policy to use for learning.</dd></dl>
</li>
</ul>
<a name="setMaximumEpisodesForPlanning(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaximumEpisodesForPlanning</h4>
<pre>public&nbsp;void&nbsp;setMaximumEpisodesForPlanning(int&nbsp;n)</pre>
<div class="block">Sets the maximum number of episodes that will be performed when the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>n</code> - the maximum number of episodes that will be performed when the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</dd></dl>
</li>
</ul>
<a name="setMaxQChangeForPlanningTerminaiton(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaxQChangeForPlanningTerminaiton</h4>
<pre>public&nbsp;void&nbsp;setMaxQChangeForPlanningTerminaiton(double&nbsp;m)</pre>
<div class="block">Sets a max change in the Q-function threshold that will cause the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearning.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> to stop planning
 when it is achieved.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>m</code> - the maximum allowable change in the Q-function before planning stops</dd></dl>
</li>
</ul>
<a name="getLastNumSteps()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastNumSteps</h4>
<pre>public&nbsp;int&nbsp;getLastNumSteps()</pre>
<div class="block">Returns the number of steps taken in the last episode;</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the number of steps taken in the last episode;</dd></dl>
</li>
</ul>
<a name="toggleShouldDecomposeOption(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toggleShouldDecomposeOption</h4>
<pre>public&nbsp;void&nbsp;toggleShouldDecomposeOption(boolean&nbsp;toggle)</pre>
<div class="block">Sets whether the primitive actions taken during an options will be included as steps in produced EpisodeAnalysis objects.
 The default value is true. If this is set to false, then EpisodeAnalysis objects returned from a learning episode will record options
 as a single "action" and the steps taken by the option will be hidden.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>toggle</code> - whether to decompose options into the primitive actions taken by them or not.</dd></dl>
</li>
</ul>
<a name="toggleShouldAnnotateOptionDecomposition(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toggleShouldAnnotateOptionDecomposition</h4>
<pre>public&nbsp;void&nbsp;toggleShouldAnnotateOptionDecomposition(boolean&nbsp;toggle)</pre>
<div class="block">Sets whether options that are decomposed into primitives will have the option that produced them and listed.
 The default value is true. If option decomposition is not enabled, changing this value will do nothing. When it
 is enabled and this is set to true, primitive actions taken by an option in EpisodeAnalysis objects will be
 recorded with a special action name that indicates which option was called to produce the primitive action
 as well as which step of the option the primitive action is. When set to false, recorded names of primitives
 will be only the primitive aciton's name it will be unclear which option was taken to generate it.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>toggle</code> - whether to annotate the primitive actions of options with the calling option's name.</dd></dl>
</li>
</ul>
<a name="getQs(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQs</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;&nbsp;getQs(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQs(burlap.oomdp.core.State)">QComputablePlanner</a></code></strong></div>
<div class="block">Returns a <code>List</code> of <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQs(burlap.oomdp.core.State)">getQs</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the state for which Q-values are to be returned.</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>List</code> of <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</dd></dl>
</li>
</ul>
<a name="getQ(burlap.oomdp.core.State, burlap.oomdp.core.AbstractGroundedAction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQ</h4>
<pre>public&nbsp;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&nbsp;getQ(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
          <a href="../../../../../burlap/oomdp/core/AbstractGroundedAction.html" title="class in burlap.oomdp.core">AbstractGroundedAction</a>&nbsp;a)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">QComputablePlanner</a></code></strong></div>
<div class="block">Returns the <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">getQ</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the input state</dd><dd><code>a</code> - the input action</dd>
<dt><span class="strong">Returns:</span></dt><dd>the <a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</dd></dl>
</li>
</ul>
<a name="getQs(burlap.behavior.statehashing.StateHashTuple)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQs</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;&nbsp;getQs(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</pre>
<div class="block">Returns the possible Q-values for a given hashed stated.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the hashed state for which to get the Q-values.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the possible Q-values for a given hashed stated.</dd></dl>
</li>
</ul>
<a name="getQ(burlap.behavior.statehashing.StateHashTuple, burlap.oomdp.singleagent.GroundedAction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQ</h4>
<pre>protected&nbsp;<a href="../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&nbsp;getQ(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s,
          <a href="../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;a)</pre>
<div class="block">Returns the Q-value for a given hashed state and action.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the hashed state</dd><dd><code>a</code> - the action</dd>
<dt><span class="strong">Returns:</span></dt><dd>the Q-value for a given hashed state and action; null is returned if there is not Q-value currently stored.</dd></dl>
</li>
</ul>
<a name="getStateNode(burlap.behavior.statehashing.StateHashTuple)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStateNode</h4>
<pre>protected&nbsp;<a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods">QLearningStateNode</a>&nbsp;getStateNode(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</pre>
<div class="block">Returns the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object stored for the given hashed state. If no <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object.
 is stored, then it is created and has its Q-value initialize using this objects <a href="../../../../../burlap/behavior/singleagent/ValueFunctionInitialization.html" title="interface in burlap.behavior.singleagent"><code>ValueFunctionInitialization</code></a> data member.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the hashed state for which to get the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object</dd>
<dt><span class="strong">Returns:</span></dt><dd>the <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object stored for the given hashed state. If no <a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><code>QLearningStateNode</code></a> object.</dd></dl>
</li>
</ul>
<a name="getMaxQ(burlap.behavior.statehashing.StateHashTuple)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMaxQ</h4>
<pre>protected&nbsp;double&nbsp;getMaxQ(<a href="../../../../../burlap/behavior/statehashing/StateHashTuple.html" title="class in burlap.behavior.statehashing">StateHashTuple</a>&nbsp;s)</pre>
<div class="block">Returns the maximum Q-value in the hashed stated.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the state for which to get he maximum Q-value;</dd>
<dt><span class="strong">Returns:</span></dt><dd>the maximum Q-value in the hashed stated.</dd></dl>
</li>
</ul>
<a name="planFromState(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>planFromState</h4>
<pre>public&nbsp;void&nbsp;planFromState(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)">OOMDPPlanner</a></code></strong></div>
<div class="block">This method will cause the planner to begin planning from the specified initial state</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)">planFromState</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - the initial state of the planning problem</dd></dl>
</li>
</ul>
<a name="runLearningEpisodeFrom(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runLearningEpisodeFrom</h4>
<pre>public&nbsp;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;runLearningEpisodeFrom(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">LearningAgent</a></code></strong></div>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state. The episode terminates when a terminal
 state is reached or if the agent decides to determinate the episode (e.g., by having an internal parameter set for a
 maximum number of steps in an episode).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">runLearningEpisodeFrom</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - The initial state in which the agent will start the episode.</dd>
<dt><span class="strong">Returns:</span></dt><dd>The learning episode events that was performed, stored in an <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> object.</dd></dl>
</li>
</ul>
<a name="runLearningEpisodeFrom(burlap.oomdp.core.State, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runLearningEpisodeFrom</h4>
<pre>public&nbsp;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;runLearningEpisodeFrom(<a href="../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                                     int&nbsp;maxSteps)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">LearningAgent</a></code></strong></div>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state. The episode terminates when a terminal
 state is reached, if the agent decides to determinate the episode, or if the number of steps reaches the provided threshold.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - The initial state in which the agent will start the episode.</dd><dd><code>maxSteps</code> - the maximum number of steps in the episode</dd>
<dt><span class="strong">Returns:</span></dt><dd>The learning episode events that was performed, stored in an <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> object.</dd></dl>
</li>
</ul>
<a name="getLastLearningEpisode()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastLearningEpisode</h4>
<pre>public&nbsp;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;getLastLearningEpisode()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getLastLearningEpisode()">LearningAgent</a></code></strong></div>
<div class="block">Returns the last learning episode of the agent.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getLastLearningEpisode()">getLastLearningEpisode</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the last learning episode of the agent.</dd></dl>
</li>
</ul>
<a name="setNumEpisodesToStore(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setNumEpisodesToStore</h4>
<pre>public&nbsp;void&nbsp;setNumEpisodesToStore(int&nbsp;numEps)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#setNumEpisodesToStore(int)">LearningAgent</a></code></strong></div>
<div class="block">Tells the agent how many <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects representing learning episodes to internally store.
 For instance, if the number of set to 5, then the agent should remember the save the last 5 learning episodes. Note that this number
 has nothing to do with how learning is performed; it is purely for performance gathering.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#setNumEpisodesToStore(int)">setNumEpisodesToStore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>numEps</code> - the number of learning episodes to remember.</dd></dl>
</li>
</ul>
<a name="getAllStoredLearningEpisodes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllStoredLearningEpisodes</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;&nbsp;getAllStoredLearningEpisodes()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getAllStoredLearningEpisodes()">LearningAgent</a></code></strong></div>
<div class="block">Returns all saved <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getAllStoredLearningEpisodes()">getAllStoredLearningEpisodes</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>all saved <a href="../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</dd></dl>
</li>
</ul>
<a name="resetPlannerResults()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>resetPlannerResults</h4>
<pre>public&nbsp;void&nbsp;resetPlannerResults()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#resetPlannerResults()">OOMDPPlanner</a></code></strong></div>
<div class="block">Use this method to reset all planner results so that planning can be started fresh with a call to <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a>
 as if no planning had ever been performed before. Specifically, data produced from calls to the 
 <a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a> will be cleared, but all other planner settings should remain the same.
 This is useful if the reward function or transition dynamics have changed, thereby
 requiring new results to be computed. If there were other objects this planner was provided that may have changed
 and need to be reset, you will need to reset them yourself. For instance, if you told a planner to follow a policy
 that had a temperature parameter decrease with time, you will need to reset the policy's temperature yourself.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#resetPlannerResults()">resetPlannerResults</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></code></dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../burlap/behavior/singleagent/learning/tdmethods/QLearningStateNode.html" title="class in burlap.behavior.singleagent.learning.tdmethods"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/QLearning.html" target="_top">Frames</a></li>
<li><a href="QLearning.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
