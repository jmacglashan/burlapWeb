<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_67) on Thu Jun 18 17:18:35 EDT 2015 -->
<title>GradientDescentSarsaLam</title>
<meta name="date" content="2015-06-18">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="GradientDescentSarsaLam";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.EligibilityTraceVector.html" title="class in burlap.behavior.singleagent.learning.tdmethods.vfa"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html" target="_top">Frames</a></li>
<li><a href="GradientDescentSarsaLam.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">burlap.behavior.singleagent.learning.tdmethods.vfa</div>
<h2 title="Class GradientDescentSarsaLam" class="title">Class GradientDescentSarsaLam</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">burlap.behavior.singleagent.planning.OOMDPPlanner</a></li>
<li>
<ul class="inheritance">
<li>burlap.behavior.singleagent.learning.tdmethods.vfa.GradientDescentSarsaLam</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">GradientDescentSarsaLam</span>
extends <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a>
implements <a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a>, <a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></pre>
<div class="block">Gradient Descent SARSA(\lambda) implementation [1]. This implementation will work correctly with options [2]. This implementation will work
 with both linear and non-linear value function approximations by using the gradient value provided to it through the 
 <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa"><code>ValueFunctionApproximation</code></a> interface provided. <p/>The implementation can either be used for learning or planning,
 the latter of which is performed by running many learning episodes in succession. The number of episodes used for planning can be determined
 by a threshold maximum number of episodes, or by a maximum change in the VFA weight threshold.</div>
<dl><dt><span class="strong">Author:</span></dt>
  <dd>James MacGlashan
 
 <p/>
 1. Rummery, Gavin A., and Mahesan Niranjan. On-line Q-learning using connectionist systems. University of Cambridge, Department of Engineering, 1994. <br/>
 2. 2. Sutton, Richard S., Doina Precup, and Satinder Singh. "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning." Artificial intelligence 112.1 (1999): 181-211.</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.EligibilityTraceVector.html" title="class in burlap.behavior.singleagent.learning.tdmethods.vfa">GradientDescentSarsaLam.EligibilityTraceVector</a></strong></code>
<div class="block">An object for keeping track of the eligibility traces within an episode for each VFA weight</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.planning.QComputablePlanner">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></h3>
<code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.QComputablePlannerHelper.html" title="class in burlap.behavior.singleagent.planning">QComputablePlanner.QComputablePlannerHelper</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_burlap.behavior.singleagent.learning.LearningAgent">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;burlap.behavior.singleagent.learning.<a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></h3>
<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.LearningAgentBookKeeping.html" title="class in burlap.behavior.singleagent.learning">LearningAgent.LearningAgentBookKeeping</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.LinkedList&lt;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#episodeHistory">episodeHistory</a></strong></code>
<div class="block">the saved previous learning episodes</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#eStepCounter">eStepCounter</a></strong></code>
<div class="block">A counter for counting the number of steps in an episode that have been taken thus far</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#lambda">lambda</a></strong></code>
<div class="block">the strength of eligibility traces (0 for one step, 1 for full propagation)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#learningPolicy">learningPolicy</a></strong></code>
<div class="block">The learning policy to use.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#learningRate">learningRate</a></strong></code>
<div class="block">A learning rate function to use</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#maxEpisodeSize">maxEpisodeSize</a></strong></code>
<div class="block">The maximum number of steps that will be taken in an episode before the agent terminates a learning episode</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#maxWeightChangeForPlanningTermination">maxWeightChangeForPlanningTermination</a></strong></code>
<div class="block">The maximum allowable change in the VFA weights during an episode before the planning method terminates.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#maxWeightChangeInLastEpisode">maxWeightChangeInLastEpisode</a></strong></code>
<div class="block">The maximum VFA weight change that occurred in the last learning episode.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#minEligibityForUpdate">minEligibityForUpdate</a></strong></code>
<div class="block">The minimum eligibility value of a trace that will cause it to be updated</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#numEpisodesForPlanning">numEpisodesForPlanning</a></strong></code>
<div class="block">The maximum number of episodes to use for planning</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#numEpisodesToStore">numEpisodesToStore</a></strong></code>
<div class="block">The number of the most recent learning episodes to store.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#shouldAnnotateOptions">shouldAnnotateOptions</a></strong></code>
<div class="block">Whether decomposed options should have their primitive actions annotated with the options name in the returned <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#shouldDecomposeOptions">shouldDecomposeOptions</a></strong></code>
<div class="block">Whether options should be decomposed into actions in the returned <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#totalNumberOfSteps">totalNumberOfSteps</a></strong></code>
<div class="block">The total number of learning steps performed by this agent.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#useFeatureWiseLearningRate">useFeatureWiseLearningRate</a></strong></code>
<div class="block">Whether the learning rate polls should be based on the VFA state features or OO-MDP state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#useReplacingTraces">useReplacingTraces</a></strong></code>
<div class="block">Whether to use accumulating or replacing eligibility traces.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#vfa">vfa</a></strong></code>
<div class="block">The object that performs value function approximation</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="fields_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#actions">actions</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#containsParameterizedActions">containsParameterizedActions</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#debugCode">debugCode</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#domain">domain</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#gamma">gamma</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#hashingFactory">hashingFactory</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#mapToStateIndex">mapToStateIndex</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#rf">rf</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#tf">tf</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#GradientDescentSarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.singleagent.vfa.ValueFunctionApproximation,%20double,%20double)">GradientDescentSarsaLam</a></strong>(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy and places no limit on the number of steps the 
 agent can take in an episode.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#GradientDescentSarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.singleagent.vfa.ValueFunctionApproximation,%20double,%20int,%20double)">GradientDescentSarsaLam</a></strong>(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       int&nbsp;maxEpisodeSize,
                       double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy.</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#GradientDescentSarsaLam(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.singleagent.vfa.ValueFunctionApproximation,%20double,%20burlap.behavior.singleagent.Policy,%20int,%20double)">GradientDescentSarsaLam</a></strong>(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       <a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
                       int&nbsp;maxEpisodeSize,
                       double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#GDSLInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.singleagent.vfa.ValueFunctionApproximation,%20double,%20burlap.behavior.singleagent.Policy,%20int,%20double)">GDSLInit</a></strong>(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
        <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
        <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
        double&nbsp;gamma,
        <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
        double&nbsp;learningRate,
        <a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
        int&nbsp;maxEpisodeSize,
        double&nbsp;lambda)</code>
<div class="block">Initializes SARSA(\lambda) By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getActionApproximation(burlap.oomdp.core.State,%20burlap.oomdp.singleagent.GroundedAction)">getActionApproximation</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
                      <a href="../../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;ga)</code>
<div class="block">Returns the VFA Q-value approximation for the given state and action.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getAllActionApproximations(burlap.oomdp.core.State)">getAllActionApproximations</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</code>
<div class="block">Gets all Q-value VFA results for each action for a given state</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getAllStoredLearningEpisodes()">getAllStoredLearningEpisodes</a></strong>()</code>
<div class="block">Returns all saved <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getLastLearningEpisode()">getLastLearningEpisode</a></strong>()</code>
<div class="block">Returns the last learning episode of the agent.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getLastNumSteps()">getLastNumSteps</a></strong>()</code>
<div class="block">Returns the number of steps taken in the last episode;</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">getQ</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
    <a href="../../../../../../burlap/oomdp/core/AbstractGroundedAction.html" title="class in burlap.oomdp.core">AbstractGroundedAction</a>&nbsp;a)</code>
<div class="block">Returns the <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getQFromFeaturesFor(java.util.List,%20burlap.oomdp.core.State,%20burlap.oomdp.singleagent.GroundedAction)">getQFromFeaturesFor</a></strong>(java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a>&gt;&nbsp;results,
                   <a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
                   <a href="../../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;ga)</code>
<div class="block">Creates a Q-value object in which the Q-value is determined from VFA.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#getQs(burlap.oomdp.core.State)">getQs</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</code>
<div class="block">Returns a <code>List</code> of <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)">planFromState</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</code>
<div class="block">This method will cause the planner to begin planning from the specified initial state</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#resetPlannerResults()">resetPlannerResults</a></strong>()</code>
<div class="block">Use this method to reset all planner results so that planning can be started fresh with a call to <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a>
 as if no planning had ever been performed before.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">runLearningEpisodeFrom</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</code>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></strong>(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                      int&nbsp;maxSteps)</code>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setLearningPolicy(burlap.behavior.singleagent.Policy)">setLearningPolicy</a></strong>(<a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;p)</code>
<div class="block">Sets which policy this agent should use for learning.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setLearningRate(burlap.behavior.learningrate.LearningRate)">setLearningRate</a></strong>(<a href="../../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a>&nbsp;lr)</code>
<div class="block">Sets the learning rate function to use.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setMaximumEpisodesForPlanning(int)">setMaximumEpisodesForPlanning</a></strong>(int&nbsp;n)</code>
<div class="block">Sets the maximum number of episodes that will be performed when the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setMaxVFAWeightChangeForPlanningTerminaiton(double)">setMaxVFAWeightChangeForPlanningTerminaiton</a></strong>(double&nbsp;m)</code>
<div class="block">Sets a max change in the VFA weight threshold that will cause the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> to stop planning
 when it is achieved.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setNumEpisodesToStore(int)">setNumEpisodesToStore</a></strong>(int&nbsp;numEps)</code>
<div class="block">Tells the agent how many <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects representing learning episodes to internally store.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setUseFeatureWiseLearningRate(boolean)">setUseFeatureWiseLearningRate</a></strong>(boolean&nbsp;useFeatureWiseLearningRate)</code>
<div class="block">Sets whether learning rate polls should be based on the VFA state feature ids, or the OO-MDP state.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#setUseReplaceTraces(boolean)">setUseReplaceTraces</a></strong>(boolean&nbsp;toggle)</code>
<div class="block">Sets whether to use replacing eligibility traces rather than accumulating traces.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#toggleShouldAnnotateOptionDecomposition(boolean)">toggleShouldAnnotateOptionDecomposition</a></strong>(boolean&nbsp;toggle)</code>
<div class="block">Sets whether options that are decomposed into primitives will have the option that produced them and listed.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#toggleShouldDecomposeOption(boolean)">toggleShouldDecomposeOption</a></strong>(boolean&nbsp;toggle)</code>
<div class="block">Sets whether the primitive actions taken during an options will be included as steps in produced EpisodeAnalysis objects.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_burlap.behavior.singleagent.planning.OOMDPPlanner">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;burlap.behavior.singleagent.planning.<a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></h3>
<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#addNonDomainReferencedAction(burlap.oomdp.singleagent.Action)">addNonDomainReferencedAction</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getActions()">getActions</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getAllGroundedActions(burlap.oomdp.core.State)">getAllGroundedActions</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDebugCode()">getDebugCode</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getDomain()">getDomain</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getGamma()">getGamma</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getHashingFactory()">getHashingFactory</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRf()">getRf</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getRF()">getRF</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTf()">getTf</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#getTF()">getTF</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#plannerInit(burlap.oomdp.core.Domain,%20burlap.oomdp.singleagent.RewardFunction,%20burlap.oomdp.core.TerminalFunction,%20double,%20burlap.behavior.statehashing.StateHashFactory)">plannerInit</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setActions(java.util.List)">setActions</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDebugCode(int)">setDebugCode</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setDomain(burlap.oomdp.core.Domain)">setDomain</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setGamma(double)">setGamma</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setRf(burlap.oomdp.singleagent.RewardFunction)">setRf</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#setTf(burlap.oomdp.core.TerminalFunction)">setTf</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#stateHash(burlap.oomdp.core.State)">stateHash</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#toggleDebugPrinting(boolean)">toggleDebugPrinting</a>, <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#translateAction(burlap.oomdp.singleagent.GroundedAction,%20java.util.Map)">translateAction</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="vfa">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>vfa</h4>
<pre>protected&nbsp;<a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a> vfa</pre>
<div class="block">The object that performs value function approximation</div>
</li>
</ul>
<a name="learningRate">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>learningRate</h4>
<pre>protected&nbsp;<a href="../../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a> learningRate</pre>
<div class="block">A learning rate function to use</div>
</li>
</ul>
<a name="learningPolicy">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>learningPolicy</h4>
<pre>protected&nbsp;<a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a> learningPolicy</pre>
<div class="block">The learning policy to use. Typically these will be policies that link back to this object so that they change as the Q-value estimate change.</div>
</li>
</ul>
<a name="lambda">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>lambda</h4>
<pre>protected&nbsp;double lambda</pre>
<div class="block">the strength of eligibility traces (0 for one step, 1 for full propagation)</div>
</li>
</ul>
<a name="maxEpisodeSize">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxEpisodeSize</h4>
<pre>protected&nbsp;int maxEpisodeSize</pre>
<div class="block">The maximum number of steps that will be taken in an episode before the agent terminates a learning episode</div>
</li>
</ul>
<a name="eStepCounter">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>eStepCounter</h4>
<pre>protected&nbsp;int eStepCounter</pre>
<div class="block">A counter for counting the number of steps in an episode that have been taken thus far</div>
</li>
</ul>
<a name="numEpisodesForPlanning">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numEpisodesForPlanning</h4>
<pre>protected&nbsp;int numEpisodesForPlanning</pre>
<div class="block">The maximum number of episodes to use for planning</div>
</li>
</ul>
<a name="maxWeightChangeForPlanningTermination">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxWeightChangeForPlanningTermination</h4>
<pre>protected&nbsp;double maxWeightChangeForPlanningTermination</pre>
<div class="block">The maximum allowable change in the VFA weights during an episode before the planning method terminates.</div>
</li>
</ul>
<a name="maxWeightChangeInLastEpisode">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maxWeightChangeInLastEpisode</h4>
<pre>protected&nbsp;double maxWeightChangeInLastEpisode</pre>
<div class="block">The maximum VFA weight change that occurred in the last learning episode.</div>
</li>
</ul>
<a name="useFeatureWiseLearningRate">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useFeatureWiseLearningRate</h4>
<pre>protected&nbsp;boolean useFeatureWiseLearningRate</pre>
<div class="block">Whether the learning rate polls should be based on the VFA state features or OO-MDP state. If true, then based on feature VFA state features; if false then the OO-MDP state.
 Default is to use feature ids.</div>
</li>
</ul>
<a name="minEligibityForUpdate">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>minEligibityForUpdate</h4>
<pre>protected&nbsp;double minEligibityForUpdate</pre>
<div class="block">The minimum eligibility value of a trace that will cause it to be updated</div>
</li>
</ul>
<a name="episodeHistory">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>episodeHistory</h4>
<pre>protected&nbsp;java.util.LinkedList&lt;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt; episodeHistory</pre>
<div class="block">the saved previous learning episodes</div>
</li>
</ul>
<a name="numEpisodesToStore">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numEpisodesToStore</h4>
<pre>protected&nbsp;int numEpisodesToStore</pre>
<div class="block">The number of the most recent learning episodes to store.</div>
</li>
</ul>
<a name="useReplacingTraces">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>useReplacingTraces</h4>
<pre>protected&nbsp;boolean useReplacingTraces</pre>
<div class="block">Whether to use accumulating or replacing eligibility traces.</div>
</li>
</ul>
<a name="shouldDecomposeOptions">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>shouldDecomposeOptions</h4>
<pre>protected&nbsp;boolean shouldDecomposeOptions</pre>
<div class="block">Whether options should be decomposed into actions in the returned <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</li>
</ul>
<a name="shouldAnnotateOptions">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>shouldAnnotateOptions</h4>
<pre>protected&nbsp;boolean shouldAnnotateOptions</pre>
<div class="block">Whether decomposed options should have their primitive actions annotated with the options name in the returned <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects.</div>
</li>
</ul>
<a name="totalNumberOfSteps">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>totalNumberOfSteps</h4>
<pre>protected&nbsp;int totalNumberOfSteps</pre>
<div class="block">The total number of learning steps performed by this agent.</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="GradientDescentSarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.singleagent.vfa.ValueFunctionApproximation, double, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>GradientDescentSarsaLam</h4>
<pre>public&nbsp;GradientDescentSarsaLam(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy and places no limit on the number of steps the 
 agent can take in an episode. By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>vfa</code> - the value function approximation method to use for estimate Q-values</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="GradientDescentSarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.singleagent.vfa.ValueFunctionApproximation, double, int, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>GradientDescentSarsaLam</h4>
<pre>public&nbsp;GradientDescentSarsaLam(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       int&nbsp;maxEpisodeSize,
                       double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) with 0.1 epsilon greedy policy. By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>vfa</code> - the value function approximation method to use for estimate Q-values</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in an episode before terminating</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="GradientDescentSarsaLam(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.singleagent.vfa.ValueFunctionApproximation, double, burlap.behavior.singleagent.Policy, int, double)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>GradientDescentSarsaLam</h4>
<pre>public&nbsp;GradientDescentSarsaLam(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
                       <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
                       <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
                       double&nbsp;gamma,
                       <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
                       double&nbsp;learningRate,
                       <a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
                       int&nbsp;maxEpisodeSize,
                       double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>vfa</code> - the value function approximation method to use for estimate Q-values</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in an episode before terminating</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="GDSLInit(burlap.oomdp.core.Domain, burlap.oomdp.singleagent.RewardFunction, burlap.oomdp.core.TerminalFunction, double, burlap.behavior.singleagent.vfa.ValueFunctionApproximation, double, burlap.behavior.singleagent.Policy, int, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>GDSLInit</h4>
<pre>protected&nbsp;void&nbsp;GDSLInit(<a href="../../../../../../burlap/oomdp/core/Domain.html" title="class in burlap.oomdp.core">Domain</a>&nbsp;domain,
            <a href="../../../../../../burlap/oomdp/singleagent/RewardFunction.html" title="interface in burlap.oomdp.singleagent">RewardFunction</a>&nbsp;rf,
            <a href="../../../../../../burlap/oomdp/core/TerminalFunction.html" title="interface in burlap.oomdp.core">TerminalFunction</a>&nbsp;tf,
            double&nbsp;gamma,
            <a href="../../../../../../burlap/behavior/singleagent/vfa/ValueFunctionApproximation.html" title="interface in burlap.behavior.singleagent.vfa">ValueFunctionApproximation</a>&nbsp;vfa,
            double&nbsp;learningRate,
            <a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;learningPolicy,
            int&nbsp;maxEpisodeSize,
            double&nbsp;lambda)</pre>
<div class="block">Initializes SARSA(\lambda) By default the agent will only save the last learning episode and a call to the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method
 will cause the planner to use only one episode for planning; this should probably be changed to a much larger value if you plan on using this
 algorithm as a planning algorithm.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>domain</code> - the domain in which to learn</dd><dd><code>rf</code> - the reward function</dd><dd><code>tf</code> - the terminal function</dd><dd><code>gamma</code> - the discount factor</dd><dd><code>vfa</code> - the value function approximation method to use for estimate Q-values</dd><dd><code>learningRate</code> - the learning rate</dd><dd><code>learningPolicy</code> - the learning policy to follow during a learning episode.</dd><dd><code>maxEpisodeSize</code> - the maximum number of steps the agent will take in an episode before terminating</dd><dd><code>lambda</code> - specifies the strength of eligibility traces (0 for one step, 1 for full propagation)</dd></dl>
</li>
</ul>
<a name="setLearningRate(burlap.behavior.learningrate.LearningRate)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRate</h4>
<pre>public&nbsp;void&nbsp;setLearningRate(<a href="../../../../../../burlap/behavior/learningrate/LearningRate.html" title="interface in burlap.behavior.learningrate">LearningRate</a>&nbsp;lr)</pre>
<div class="block">Sets the learning rate function to use.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lr</code> - the learning rate function to use.</dd></dl>
</li>
</ul>
<a name="setUseFeatureWiseLearningRate(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUseFeatureWiseLearningRate</h4>
<pre>public&nbsp;void&nbsp;setUseFeatureWiseLearningRate(boolean&nbsp;useFeatureWiseLearningRate)</pre>
<div class="block">Sets whether learning rate polls should be based on the VFA state feature ids, or the OO-MDP state. Default is to use feature ids.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>useFeatureWiseLearningRate</code> - if true then learning rate polls are based on VFA state feature ids; if false then they are based on the OO-MDP state object.</dd></dl>
</li>
</ul>
<a name="setLearningPolicy(burlap.behavior.singleagent.Policy)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningPolicy</h4>
<pre>public&nbsp;void&nbsp;setLearningPolicy(<a href="../../../../../../burlap/behavior/singleagent/Policy.html" title="class in burlap.behavior.singleagent">Policy</a>&nbsp;p)</pre>
<div class="block">Sets which policy this agent should use for learning.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>p</code> - the policy to use for learning.</dd></dl>
</li>
</ul>
<a name="setMaximumEpisodesForPlanning(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaximumEpisodesForPlanning</h4>
<pre>public&nbsp;void&nbsp;setMaximumEpisodesForPlanning(int&nbsp;n)</pre>
<div class="block">Sets the maximum number of episodes that will be performed when the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>n</code> - the maximum number of episodes that will be performed when the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> method is called.</dd></dl>
</li>
</ul>
<a name="setMaxVFAWeightChangeForPlanningTerminaiton(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaxVFAWeightChangeForPlanningTerminaiton</h4>
<pre>public&nbsp;void&nbsp;setMaxVFAWeightChangeForPlanningTerminaiton(double&nbsp;m)</pre>
<div class="block">Sets a max change in the VFA weight threshold that will cause the <a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html#planFromState(burlap.oomdp.core.State)"><code>planFromState(State)</code></a> to stop planning
 when it is achieved.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>m</code> - the maximum allowable change in the VFA weights before planning stops</dd></dl>
</li>
</ul>
<a name="getLastNumSteps()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastNumSteps</h4>
<pre>public&nbsp;int&nbsp;getLastNumSteps()</pre>
<div class="block">Returns the number of steps taken in the last episode;</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the number of steps taken in the last episode;</dd></dl>
</li>
</ul>
<a name="setUseReplaceTraces(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUseReplaceTraces</h4>
<pre>public&nbsp;void&nbsp;setUseReplaceTraces(boolean&nbsp;toggle)</pre>
<div class="block">Sets whether to use replacing eligibility traces rather than accumulating traces.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>toggle</code> - </dd></dl>
</li>
</ul>
<a name="toggleShouldDecomposeOption(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toggleShouldDecomposeOption</h4>
<pre>public&nbsp;void&nbsp;toggleShouldDecomposeOption(boolean&nbsp;toggle)</pre>
<div class="block">Sets whether the primitive actions taken during an options will be included as steps in produced EpisodeAnalysis objects.
 The default value is true. If this is set to false, then EpisodeAnalysis objects returned from a learning episode will record options
 as a single "action" and the steps taken by the option will be hidden.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>toggle</code> - whether to decompose options into the primitive actions taken by them or not.</dd></dl>
</li>
</ul>
<a name="toggleShouldAnnotateOptionDecomposition(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toggleShouldAnnotateOptionDecomposition</h4>
<pre>public&nbsp;void&nbsp;toggleShouldAnnotateOptionDecomposition(boolean&nbsp;toggle)</pre>
<div class="block">Sets whether options that are decomposed into primitives will have the option that produced them and listed.
 The default value is true. If option decomposition is not enabled, changing this value will do nothing. When it
 is enabled and this is set to true, primitive actions taken by an option in EpisodeAnalysis objects will be
 recorded with a special action name that indicates which option was called to produce the primitive action
 as well as which step of the option the primitive action is. When set to false, recorded names of primitives
 will be only the primitive aciton's name it will be unclear which option was taken to generate it.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>toggle</code> - whether to annotate the primitive actions of options with the calling option's name.</dd></dl>
</li>
</ul>
<a name="runLearningEpisodeFrom(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runLearningEpisodeFrom</h4>
<pre>public&nbsp;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;runLearningEpisodeFrom(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">LearningAgent</a></code></strong></div>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state. The episode terminates when a terminal
 state is reached or if the agent decides to determinate the episode (e.g., by having an internal parameter set for a
 maximum number of steps in an episode).</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State)">runLearningEpisodeFrom</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - The initial state in which the agent will start the episode.</dd>
<dt><span class="strong">Returns:</span></dt><dd>The learning episode events that was performed, stored in an <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> object.</dd></dl>
</li>
</ul>
<a name="runLearningEpisodeFrom(burlap.oomdp.core.State, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runLearningEpisodeFrom</h4>
<pre>public&nbsp;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;runLearningEpisodeFrom(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState,
                                     int&nbsp;maxSteps)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">LearningAgent</a></code></strong></div>
<div class="block">Causes the agent to perform a learning episode starting in the given initial state. The episode terminates when a terminal
 state is reached, if the agent decides to determinate the episode, or if the number of steps reaches the provided threshold.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#runLearningEpisodeFrom(burlap.oomdp.core.State,%20int)">runLearningEpisodeFrom</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - The initial state in which the agent will start the episode.</dd><dd><code>maxSteps</code> - the maximum number of steps in the episode</dd>
<dt><span class="strong">Returns:</span></dt><dd>The learning episode events that was performed, stored in an <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> object.</dd></dl>
</li>
</ul>
<a name="getLastLearningEpisode()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastLearningEpisode</h4>
<pre>public&nbsp;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&nbsp;getLastLearningEpisode()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getLastLearningEpisode()">LearningAgent</a></code></strong></div>
<div class="block">Returns the last learning episode of the agent.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getLastLearningEpisode()">getLastLearningEpisode</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>the last learning episode of the agent.</dd></dl>
</li>
</ul>
<a name="setNumEpisodesToStore(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setNumEpisodesToStore</h4>
<pre>public&nbsp;void&nbsp;setNumEpisodesToStore(int&nbsp;numEps)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#setNumEpisodesToStore(int)">LearningAgent</a></code></strong></div>
<div class="block">Tells the agent how many <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects representing learning episodes to internally store.
 For instance, if the number of set to 5, then the agent should remember the save the last 5 learning episodes. Note that this number
 has nothing to do with how learning is performed; it is purely for performance gathering.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#setNumEpisodesToStore(int)">setNumEpisodesToStore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>numEps</code> - the number of learning episodes to remember.</dd></dl>
</li>
</ul>
<a name="getAllStoredLearningEpisodes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllStoredLearningEpisodes</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent">EpisodeAnalysis</a>&gt;&nbsp;getAllStoredLearningEpisodes()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getAllStoredLearningEpisodes()">LearningAgent</a></code></strong></div>
<div class="block">Returns all saved <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html#getAllStoredLearningEpisodes()">getAllStoredLearningEpisodes</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/learning/LearningAgent.html" title="interface in burlap.behavior.singleagent.learning">LearningAgent</a></code></dd>
<dt><span class="strong">Returns:</span></dt><dd>all saved <a href="../../../../../../burlap/behavior/singleagent/EpisodeAnalysis.html" title="class in burlap.behavior.singleagent"><code>EpisodeAnalysis</code></a> objects of which the agent has kept track.</dd></dl>
</li>
</ul>
<a name="getQs(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQs</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&gt;&nbsp;getQs(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQs(burlap.oomdp.core.State)">QComputablePlanner</a></code></strong></div>
<div class="block">Returns a <code>List</code> of <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQs(burlap.oomdp.core.State)">getQs</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the state for which Q-values are to be returned.</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>List</code> of <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> objects for ever permissible action for the given input state.</dd></dl>
</li>
</ul>
<a name="getQ(burlap.oomdp.core.State, burlap.oomdp.core.AbstractGroundedAction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQ</h4>
<pre>public&nbsp;<a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&nbsp;getQ(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
          <a href="../../../../../../burlap/oomdp/core/AbstractGroundedAction.html" title="class in burlap.oomdp.core">AbstractGroundedAction</a>&nbsp;a)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">QComputablePlanner</a></code></strong></div>
<div class="block">Returns the <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html#getQ(burlap.oomdp.core.State,%20burlap.oomdp.core.AbstractGroundedAction)">getQ</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/QComputablePlanner.html" title="interface in burlap.behavior.singleagent.planning">QComputablePlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the input state</dd><dd><code>a</code> - the input action</dd>
<dt><span class="strong">Returns:</span></dt><dd>the <a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent"><code>QValue</code></a> for the given state-action pair.</dd></dl>
</li>
</ul>
<a name="getQFromFeaturesFor(java.util.List, burlap.oomdp.core.State, burlap.oomdp.singleagent.GroundedAction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getQFromFeaturesFor</h4>
<pre>protected&nbsp;<a href="../../../../../../burlap/behavior/singleagent/QValue.html" title="class in burlap.behavior.singleagent">QValue</a>&nbsp;getQFromFeaturesFor(java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a>&gt;&nbsp;results,
                         <a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
                         <a href="../../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;ga)</pre>
<div class="block">Creates a Q-value object in which the Q-value is determined from VFA.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>results</code> - the VFA prediction results for each action.</dd><dd><code>s</code> - the state of the Q-value</dd><dd><code>ga</code> - the action taken</dd>
<dt><span class="strong">Returns:</span></dt><dd>a Q-value object in which the Q-value is determined from VFA.</dd></dl>
</li>
</ul>
<a name="getAllActionApproximations(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllActionApproximations</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a>&gt;&nbsp;getAllActionApproximations(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s)</pre>
<div class="block">Gets all Q-value VFA results for each action for a given state</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the state for which the Q-Value VFA results should be returned.</dd>
<dt><span class="strong">Returns:</span></dt><dd>all Q-value VFA results for each action for a given state</dd></dl>
</li>
</ul>
<a name="getActionApproximation(burlap.oomdp.core.State, burlap.oomdp.singleagent.GroundedAction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getActionApproximation</h4>
<pre>protected&nbsp;<a href="../../../../../../burlap/behavior/singleagent/vfa/ActionApproximationResult.html" title="class in burlap.behavior.singleagent.vfa">ActionApproximationResult</a>&nbsp;getActionApproximation(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;s,
                                               <a href="../../../../../../burlap/oomdp/singleagent/GroundedAction.html" title="class in burlap.oomdp.singleagent">GroundedAction</a>&nbsp;ga)</pre>
<div class="block">Returns the VFA Q-value approximation for the given state and action.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - the state for which the VFA result should be returned</dd><dd><code>ga</code> - the action for which the VFA result should be returned</dd>
<dt><span class="strong">Returns:</span></dt><dd>the VFA Q-value approximation for the given state and action.</dd></dl>
</li>
</ul>
<a name="planFromState(burlap.oomdp.core.State)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>planFromState</h4>
<pre>public&nbsp;void&nbsp;planFromState(<a href="../../../../../../burlap/oomdp/core/State.html" title="class in burlap.oomdp.core">State</a>&nbsp;initialState)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)">OOMDPPlanner</a></code></strong></div>
<div class="block">This method will cause the planner to begin planning from the specified initial state</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)">planFromState</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>initialState</code> - the initial state of the planning problem</dd></dl>
</li>
</ul>
<a name="resetPlannerResults()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>resetPlannerResults</h4>
<pre>public&nbsp;void&nbsp;resetPlannerResults()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#resetPlannerResults()">OOMDPPlanner</a></code></strong></div>
<div class="block">Use this method to reset all planner results so that planning can be started fresh with a call to <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a>
 as if no planning had ever been performed before. Specifically, data produced from calls to the 
 <a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#planFromState(burlap.oomdp.core.State)"><code>OOMDPPlanner.planFromState(State)</code></a> will be cleared, but all other planner settings should remain the same.
 This is useful if the reward function or transition dynamics have changed, thereby
 requiring new results to be computed. If there were other objects this planner was provided that may have changed
 and need to be reset, you will need to reset them yourself. For instance, if you told a planner to follow a policy
 that had a temperature parameter decrease with time, you will need to reset the policy's temperature yourself.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html#resetPlannerResults()">resetPlannerResults</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../../burlap/behavior/singleagent/planning/OOMDPPlanner.html" title="class in burlap.behavior.singleagent.planning">OOMDPPlanner</a></code></dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../../../../burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.EligibilityTraceVector.html" title="class in burlap.behavior.singleagent.learning.tdmethods.vfa"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?burlap/behavior/singleagent/learning/tdmethods/vfa/GradientDescentSarsaLam.html" target="_top">Frames</a></li>
<li><a href="GradientDescentSarsaLam.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
